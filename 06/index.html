<!DOCTYPE html>
<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="apple-mobile-web-app-capable" content="yes"/>
    <meta name="apple-mobile-web-app-status-bar-style" content="black"/>
    <title>Shirley's SOFTWARE MIRROR: HALFTONE × FACE DETECTION</title>
    <link href="../style.css" type="text/css" rel="stylesheet">
    <script src="../script/jquery-2.1.0.min.js" type="text/javascript"></script>
    <script src="../script/processing.min.js" type="text/javascript"></script>
    <script src="../script/script.js" type="text/javascript"></script>
    <script type="text/javascript">
        // convenience function to get the id attribute of generated sketch html element
        function getProcessingSketchId() {
            return 'assignment06';
        }
    </script>

</head>
<body>
<div id="content">
    <div>
        <div class="assignment" >
            <iframe width="720" height="480"
                    src="https://www.youtube.com/embed/3lWMXg22S5Y?loop=1&autoplay=1&showinfo=0&controls=0"
                    frameborder="0" allowfullscreen></iframe>
        </div>
    </div>
    <div class="title" >
        <h1 id="description">Software Mirror:</h1><h1> Halftone × Face Detection </h1>
        <p>Turn your video into halftone with your faces in purple!</p>
    </div>
    <p>assignment06</p>
    <p>Hover the title to check out the documentation.</p>
    <p>
        Built with Processing and OpenCV
    </p>
    </div>
<canvas id="background" data-processing-sources="../script/background.pde"
        width="1200" height="650">
    <p>Your browser does not support the canvas tag.</p>
</canvas>
<div class="doc">
    <p>
        import processing.video.*;

        // video object
        Capture video;

        // open CV library
        import gab.opencv.*;
        import java.awt.Rectangle;

        // main open CV object (contains a ton of computer vision methods)
        OpenCV opencv;

        // array to hold all of the positions of the found faces
        Rectangle[] faces = {
        };

        // video scaling factor
        int scalingFactor = 2;


        void setup()
        {
        size(320*scalingFactor, 240*scalingFactor);
        colorMode(HSB,360,100,100);
        noStroke();

        // grab an array of our cameras
        String[] cameras = Capture.list();

        // no camera objects - no need to continue!
        if (cameras.length == 0)
        {
        println("There are no cameras available for capture.");
        exit();
        } else
        {
        // create a video object
        // note - bring this in at a low resolution so that you
        // don't make things chug too much!
        video = new Capture(this, 320, 240);

        // Start capturing the images from the camera
        video.start();

        // create our open CV object and tell it to monitor the video stream
        opencv = new OpenCV(this, video);

        // tell open CV to begin looking for faces
        opencv.loadCascade(OpenCV.CASCADE_FRONTALFACE);
        }
        }

        void draw()
        {
        background(344,20,92);

        if (video.available())
        {
        video.read();

        // tell OpenCV about this frame
        opencv.loadImage(video);
        // attempt to detect any new faces
        faces = opencv.detect();
        }

        // ask Processing to expose the pixel data in the video
        video.loadPixels();

        // we now have access to an array of pixels!
        // we can loop over it using the following loop

        // let's only look at every few pixels
        for (int x = 0; x < video.width; x += 3)
        {
        for (int y = 0; y < video.height; y += 3)
        {
        // now we have to compute our "location" in the array
        // images in Processing are technically one dimensional
        // but we normally think of images in terms of being two dimensional
        // so we can do a little math to convert the x & y position to a single dimensional position
        int location = x + y*video.width;
        float b = brightness(video.pixels[location]);
        float pixelSize = map( b, 0, 100, 10, 0);
        fill(190,50,50);
        for (int i = 0; i < faces.length; i++)
        {
        float distance = dist(x*scalingFactor,y*scalingFactor,faces[i].x*scalingFactor+faces[i].width*scalingFactor/2,faces[i].y*scalingFactor+faces[i].height*scalingFactor/2);
        if (distance<faces[i].height*1.5) {
        float hOffset = constrain(map(distance,0,faces[i].height*1.5,200,0),0,100);
        fill(190+hOffset,50,50);
        }
        }

        ellipse(x*scalingFactor, y*scalingFactor, pixelSize, pixelSize);
        }
        }
        }
    </p>
</div>
<br>

<div class="home-btn">
    <a href="../index.html"><p>HOME</p></a>
</div>
</body>
</html>
